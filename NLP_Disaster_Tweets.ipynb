{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import necessary modules","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import WordCloud,STOPWORDS  #Be VERY CAREFUL, it is \"WordCloud\" and not \"wordcloud\" after the import functioin\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-12T18:50:13.795581Z","iopub.execute_input":"2022-03-12T18:50:13.795998Z","iopub.status.idle":"2022-03-12T18:50:13.802336Z","shell.execute_reply.started":"2022-03-12T18:50:13.795934Z","shell.execute_reply":"2022-03-12T18:50:13.801319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-03-12T18:50:13.804599Z","iopub.execute_input":"2022-03-12T18:50:13.804952Z","iopub.status.idle":"2022-03-12T18:50:13.856522Z","shell.execute_reply.started":"2022-03-12T18:50:13.804891Z","shell.execute_reply":"2022-03-12T18:50:13.85552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### A quick look at the data\n\nExample of a tweet that is NOT a disaster tweet.","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:13.858392Z","iopub.execute_input":"2022-03-12T18:50:13.85882Z","iopub.status.idle":"2022-03-12T18:50:13.872723Z","shell.execute_reply.started":"2022-03-12T18:50:13.858745Z","shell.execute_reply":"2022-03-12T18:50:13.871685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"target\"] == 0][\"text\"].values[1]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:13.876144Z","iopub.execute_input":"2022-03-12T18:50:13.876586Z","iopub.status.idle":"2022-03-12T18:50:13.887537Z","shell.execute_reply.started":"2022-03-12T18:50:13.876511Z","shell.execute_reply":"2022-03-12T18:50:13.886404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And one that is:","metadata":{}},{"cell_type":"code","source":"train_df[train_df[\"target\"] == 1][\"text\"].values[1]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:13.889125Z","iopub.execute_input":"2022-03-12T18:50:13.889447Z","iopub.status.idle":"2022-03-12T18:50:13.898317Z","shell.execute_reply.started":"2022-03-12T18:50:13.889381Z","shell.execute_reply":"2022-03-12T18:50:13.897701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a duplicate dataframe\nhope = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:13.899427Z","iopub.execute_input":"2022-03-12T18:50:13.899807Z","iopub.status.idle":"2022-03-12T18:50:13.911196Z","shell.execute_reply.started":"2022-03-12T18:50:13.899765Z","shell.execute_reply":"2022-03-12T18:50:13.910393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hope.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:13.912409Z","iopub.execute_input":"2022-03-12T18:50:13.912823Z","iopub.status.idle":"2022-03-12T18:50:13.921975Z","shell.execute_reply.started":"2022-03-12T18:50:13.912781Z","shell.execute_reply":"2022-03-12T18:50:13.92121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### REMOVE HYPERLINKS","metadata":{}},{"cell_type":"code","source":"# How many rows contain hyperlinks\nhope['text'].str.contains('http?').sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:13.923073Z","iopub.execute_input":"2022-03-12T18:50:13.923486Z","iopub.status.idle":"2022-03-12T18:50:13.943089Z","shell.execute_reply.started":"2022-03-12T18:50:13.923434Z","shell.execute_reply":"2022-03-12T18:50:13.942372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove hyperlinks\ndef remove_http(review):\n    url_pattern = re.compile(r'href|http\\S+')\n    return url_pattern.sub(r'', review)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:13.944141Z","iopub.execute_input":"2022-03-12T18:50:13.944547Z","iopub.status.idle":"2022-03-12T18:50:13.949357Z","shell.execute_reply.started":"2022-03-12T18:50:13.944505Z","shell.execute_reply":"2022-03-12T18:50:13.948414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hope['text'] = hope['text'].apply(remove_http)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:13.9507Z","iopub.execute_input":"2022-03-12T18:50:13.950971Z","iopub.status.idle":"2022-03-12T18:50:13.978774Z","shell.execute_reply.started":"2022-03-12T18:50:13.950919Z","shell.execute_reply":"2022-03-12T18:50:13.978042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How many rows contain hyperlinks\nhope['text'].str.contains('http?').sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:14.045054Z","iopub.execute_input":"2022-03-12T18:50:14.045782Z","iopub.status.idle":"2022-03-12T18:50:14.064611Z","shell.execute_reply.started":"2022-03-12T18:50:14.045709Z","shell.execute_reply":"2022-03-12T18:50:14.063639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## POPULAR WORDS","metadata":{}},{"cell_type":"code","source":"#Create a single variable with all the summaries so as to make the removal of STOPWORDS faster\ntotal_text = (' '.join(hope['text']))\n\ntotal_text[0:1000]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:14.06638Z","iopub.execute_input":"2022-03-12T18:50:14.066797Z","iopub.status.idle":"2022-03-12T18:50:14.076023Z","shell.execute_reply.started":"2022-03-12T18:50:14.066755Z","shell.execute_reply":"2022-03-12T18:50:14.075197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#substitute every symbol(!\"\\'.) except(^) a-z with space in the variable \"total_text\"\ntotal_text = re.sub('[^a-zA-Z]', ' ', total_text)\n\ntotal_text[0:1000]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:14.077566Z","iopub.execute_input":"2022-03-12T18:50:14.077972Z","iopub.status.idle":"2022-03-12T18:50:14.17003Z","shell.execute_reply.started":"2022-03-12T18:50:14.077929Z","shell.execute_reply":"2022-03-12T18:50:14.169041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove excess spacing\ntotal_text = re.sub(' +', ' ', total_text)\n\ntotal_text[0:1000]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:14.171364Z","iopub.execute_input":"2022-03-12T18:50:14.17179Z","iopub.status.idle":"2022-03-12T18:50:14.228225Z","shell.execute_reply.started":"2022-03-12T18:50:14.171727Z","shell.execute_reply":"2022-03-12T18:50:14.227083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### REMOVE STOPWORDS","metadata":{}},{"cell_type":"code","source":"# Set your stopwords\nstop_words2 = set(STOPWORDS)\n\n# Set your second set of stopwords\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:14.231037Z","iopub.execute_input":"2022-03-12T18:50:14.231484Z","iopub.status.idle":"2022-03-12T18:50:14.245097Z","shell.execute_reply.started":"2022-03-12T18:50:14.231434Z","shell.execute_reply":"2022-03-12T18:50:14.244219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Find popular words i.e words that occur regularly in hope['text']\n\nwordcloud = WordCloud(width=1000, height=500, stopwords=stop_words2).generate(total_text)\n\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis('off') #to remove the axis number from showing","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:14.24765Z","iopub.execute_input":"2022-03-12T18:50:14.248039Z","iopub.status.idle":"2022-03-12T18:50:16.514873Z","shell.execute_reply.started":"2022-03-12T18:50:14.247996Z","shell.execute_reply":"2022-03-12T18:50:16.514087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize each sentence in the list sense\nword_tokens = word_tokenize(total_text)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:16.515983Z","iopub.execute_input":"2022-03-12T18:50:16.516361Z","iopub.status.idle":"2022-03-12T18:50:17.565918Z","shell.execute_reply.started":"2022-03-12T18:50:16.516319Z","shell.execute_reply":"2022-03-12T18:50:17.564774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_tokens[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:17.567425Z","iopub.execute_input":"2022-03-12T18:50:17.567729Z","iopub.status.idle":"2022-03-12T18:50:17.573725Z","shell.execute_reply.started":"2022-03-12T18:50:17.567674Z","shell.execute_reply":"2022-03-12T18:50:17.572781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list(hello) that contains stopwords and a list(filtered_sentence) that contains words without stopwords\nfiltered_sentence = []\nhello = ['amp','don','re','via','st']\nfor w in word_tokens:\n    if w in stop_words2:\n        hello.append(w)\n    else:\n        filtered_sentence.append(w)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:17.57483Z","iopub.execute_input":"2022-03-12T18:50:17.575126Z","iopub.status.idle":"2022-03-12T18:50:17.613955Z","shell.execute_reply.started":"2022-03-12T18:50:17.575072Z","shell.execute_reply":"2022-03-12T18:50:17.613226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an index for the dictionary you will be creating later on\nbark = []\nfor i in range(len(filtered_sentence)):\n    bark.append(i)\nlen(bark)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:17.615313Z","iopub.execute_input":"2022-03-12T18:50:17.615605Z","iopub.status.idle":"2022-03-12T18:50:17.635089Z","shell.execute_reply.started":"2022-03-12T18:50:17.615549Z","shell.execute_reply":"2022-03-12T18:50:17.633977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe\ndata = {\"id\": bark,\n        \"filtered_sentence\": filtered_sentence}\n  \ndf = pd.DataFrame(data)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:17.637018Z","iopub.execute_input":"2022-03-12T18:50:17.637668Z","iopub.status.idle":"2022-03-12T18:50:17.698299Z","shell.execute_reply.started":"2022-03-12T18:50:17.637591Z","shell.execute_reply":"2022-03-12T18:50:17.697344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe that shows the count of each unique word\nword_count = df['filtered_sentence'].value_counts(ascending=False)\nword_count[1:20]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:17.699888Z","iopub.execute_input":"2022-03-12T18:50:17.700531Z","iopub.status.idle":"2022-03-12T18:50:17.74439Z","shell.execute_reply.started":"2022-03-12T18:50:17.700469Z","shell.execute_reply":"2022-03-12T18:50:17.743172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list of the dictionary keys\nkey_list = list(word_count.keys())","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:17.745937Z","iopub.execute_input":"2022-03-12T18:50:17.746571Z","iopub.status.idle":"2022-03-12T18:50:17.757617Z","shell.execute_reply.started":"2022-03-12T18:50:17.746286Z","shell.execute_reply":"2022-03-12T18:50:17.75665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A list of lowercase alphabets + a list of higher alphabets + a list of words in stop_words2\nstop_words3 = list(map(chr, range(97, 123))) + list(map(chr, range(65, 90))) + hello\nstop_words3[100:110]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:17.758879Z","iopub.execute_input":"2022-03-12T18:50:17.759143Z","iopub.status.idle":"2022-03-12T18:50:17.776214Z","shell.execute_reply.started":"2022-03-12T18:50:17.759093Z","shell.execute_reply":"2022-03-12T18:50:17.775438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove redundadnt words that are not important\nfor i in key_list:\n    if word_count[i] > 184:\n        stop_words3.append(i)\n        word_count.pop(i)\n    elif word_count[i] < 5:\n        word_count.pop(i)  ","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:17.777474Z","iopub.execute_input":"2022-03-12T18:50:17.777916Z","iopub.status.idle":"2022-03-12T18:50:39.978319Z","shell.execute_reply.started":"2022-03-12T18:50:17.777862Z","shell.execute_reply":"2022-03-12T18:50:39.97753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"key_list2 = list(word_count.keys())\nkey_list2[1:20]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:39.97972Z","iopub.execute_input":"2022-03-12T18:50:39.980227Z","iopub.status.idle":"2022-03-12T18:50:39.989607Z","shell.execute_reply.started":"2022-03-12T18:50:39.980168Z","shell.execute_reply":"2022-03-12T18:50:39.988635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Find popular words i.e words that occur regularly in key_list2\ntotal_text2 = (' '.join(key_list2))\n\nwordcloud2 = WordCloud(width=1000, height=500, stopwords=stop_words3).generate(total_text2)\n\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud2)\nplt.axis('off') #to remove the axis number from showing","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:39.991117Z","iopub.execute_input":"2022-03-12T18:50:39.991515Z","iopub.status.idle":"2022-03-12T18:50:41.451678Z","shell.execute_reply.started":"2022-03-12T18:50:39.991446Z","shell.execute_reply":"2022-03-12T18:50:41.450807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VECTORIZE THE COLUMN","metadata":{"execution":{"iopub.status.busy":"2022-03-01T05:45:18.165035Z","iopub.execute_input":"2022-03-01T05:45:18.165493Z","iopub.status.idle":"2022-03-01T05:45:18.195727Z","shell.execute_reply.started":"2022-03-01T05:45:18.1653Z","shell.execute_reply":"2022-03-01T05:45:18.19484Z"}}},{"cell_type":"code","source":"count_vectorizer = feature_extraction.text.TfidfVectorizer(stop_words = stop_words3)\nexample_train_vectors = count_vectorizer.fit_transform(hope['text'][0:5])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:41.453012Z","iopub.execute_input":"2022-03-12T18:50:41.45328Z","iopub.status.idle":"2022-03-12T18:50:41.473302Z","shell.execute_reply.started":"2022-03-12T18:50:41.453211Z","shell.execute_reply":"2022-03-12T18:50:41.472291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create vectors from your training data\ntrain_vectors = count_vectorizer.fit_transform(hope['text'])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:41.500477Z","iopub.execute_input":"2022-03-12T18:50:41.500782Z","iopub.status.idle":"2022-03-12T18:50:41.733156Z","shell.execute_reply.started":"2022-03-12T18:50:41.500738Z","shell.execute_reply":"2022-03-12T18:50:41.732193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## note that I'm NOT using .fit_transform() here. Using just .transform() makes sure\n# that the tokens in the train vectors are the only ones mapped to the test vectors - \n# i.e. that the train and test vectors use the same set of tokens.\ntest_vectors = count_vectorizer.transform(test_df[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:41.735008Z","iopub.execute_input":"2022-03-12T18:50:41.735647Z","iopub.status.idle":"2022-03-12T18:50:41.834567Z","shell.execute_reply.started":"2022-03-12T18:50:41.735499Z","shell.execute_reply":"2022-03-12T18:50:41.833724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The model","metadata":{}},{"cell_type":"code","source":"## The vectors are really big, so we want to push the model's weights\n## toward 0 without completely discounting different words - ridge regression \n## is a good way to do this.\nclf = linear_model.RidgeClassifier()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:41.83599Z","iopub.execute_input":"2022-03-12T18:50:41.836315Z","iopub.status.idle":"2022-03-12T18:50:41.841045Z","shell.execute_reply.started":"2022-03-12T18:50:41.836253Z","shell.execute_reply":"2022-03-12T18:50:41.840362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### TEST THE MODEL","metadata":{}},{"cell_type":"code","source":"scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\nscores","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:41.84222Z","iopub.execute_input":"2022-03-12T18:50:41.842681Z","iopub.status.idle":"2022-03-12T18:50:41.977095Z","shell.execute_reply.started":"2022-03-12T18:50:41.842629Z","shell.execute_reply":"2022-03-12T18:50:41.976078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### FITTING THE MODEL","metadata":{}},{"cell_type":"code","source":"clf.fit(train_vectors, train_df[\"target\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:41.978389Z","iopub.execute_input":"2022-03-12T18:50:41.978646Z","iopub.status.idle":"2022-03-12T18:50:42.038036Z","shell.execute_reply.started":"2022-03-12T18:50:41.978601Z","shell.execute_reply":"2022-03-12T18:50:42.037024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:42.039895Z","iopub.execute_input":"2022-03-12T18:50:42.040218Z","iopub.status.idle":"2022-03-12T18:50:42.053146Z","shell.execute_reply.started":"2022-03-12T18:50:42.040151Z","shell.execute_reply":"2022-03-12T18:50:42.052278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[\"target\"] = clf.predict(test_vectors)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:42.055168Z","iopub.execute_input":"2022-03-12T18:50:42.055774Z","iopub.status.idle":"2022-03-12T18:50:42.061448Z","shell.execute_reply.started":"2022-03-12T18:50:42.055501Z","shell.execute_reply":"2022-03-12T18:50:42.060713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:42.06243Z","iopub.execute_input":"2022-03-12T18:50:42.06267Z","iopub.status.idle":"2022-03-12T18:50:42.078942Z","shell.execute_reply.started":"2022-03-12T18:50:42.062634Z","shell.execute_reply":"2022-03-12T18:50:42.077718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T18:50:42.080425Z","iopub.execute_input":"2022-03-12T18:50:42.080826Z","iopub.status.idle":"2022-03-12T18:50:42.594672Z","shell.execute_reply.started":"2022-03-12T18:50:42.080723Z","shell.execute_reply":"2022-03-12T18:50:42.593638Z"},"trusted":true},"execution_count":null,"outputs":[]}]}